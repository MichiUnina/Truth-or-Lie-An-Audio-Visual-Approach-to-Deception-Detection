{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10129767,"sourceType":"datasetVersion","datasetId":5806090},{"sourceId":9944759,"sourceType":"datasetVersion","datasetId":5806343}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport pywt\nimport scipy\nfrom scipy.signal.windows import hamming \nimport pandas as pd\n\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Paths","metadata":{}},{"cell_type":"code","source":"base_holdout_path = '/kaggle/input/truthlie-clean-split/TruthLie_Holdout_Stratified'\ntrain_data = base_holdout_path + '/train'\nval_data = base_holdout_path + '/val'\ntest_data = base_holdout_path + '/test'\n\ncross_validation_path = '/kaggle/input/truthlie-clean-crossvalidation/TruthLie_CrossVal_Stratified'\nfolds = [f\"{cross_validation_path}/fold_{i}\" for i in range(4)]  # Paths for each fold\n\ntrain_audio_dir = train_data + \"/Audio\"\ntrain_transcript_file = train_data + \"/Transcripts/Transcripts.xlsx\"\n\nval_audio_dir = val_data + \"/Audio\"\nval_transcript_file = val_data + \"/Transcripts/Transcripts.xlsx\"\n\ntest_audio_dir = test_data + \"/Audio\"\ntest_transcript_file = test_data + \"/Transcripts/Transcripts.xlsx\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"def pad_audio(signal, target_length):\n    \"\"\"Pads the signal to reach the required length.\"\"\"\n    return np.pad(signal, (0, max(0, target_length - len(signal))), mode=\"constant\")\n        \ndef preprocess_audio_sequential_fixed_segments(signal, sample_rate, num_segments=20, n_mfcc=13):\n    \"\"\"\n    Pre-processes an audio signal into segments:\n    - Noise filtering via STFT thresholding\n    - Normalization of the signal between -1 and 1\n    - Splitting into segments with guaranteed minimum padding\n    - Feature extraction: DWT and MFCC\n    \"\"\"    \n    # Noise filtering via STFT thresholding\n    stft = np.abs(librosa.stft(signal))\n    threshold = np.median(stft)\n    stft_filtered = np.where(stft > threshold, stft, 0)\n    signal_filtered = librosa.istft(stft_filtered)\n    \n    # Normalize signal between -1 and 1\n    normalized_signal = signal_filtered / np.max(np.abs(signal_filtered))\n    window_length = len(normalized_signal) // num_segments\n    \n    # Split the signal into segments\n    segmented_signal = []\n    for i in range(num_segments):\n        start_idx = i * window_length\n        end_idx = start_idx + window_length\n        segment = normalized_signal[start_idx:end_idx]\n        \n        # Padding to ensure minimum length\n        segment = pad_audio(segment, window_length)\n        segmented_signal.append(segment)\n    segmented_signal = np.array(segmented_signal)\n    \n    # Apply Hamming window to each segment\n    hamming_window = hamming(segmented_signal.shape[1])\n    windowed_signal = segmented_signal * hamming_window\n    \n    # Initialize the list of sequential features\n    sequence_features = []\n    for segment in windowed_signal:\n        # Wavelet decomposition (5 levels, Daubechies-4)\n        coeffs = pywt.wavedec(segment, 'db4', level=5)\n        segment_features = []\n        for coeff in coeffs:\n            variance = np.var(coeff)\n            if variance == 0:\n                kurtosis = 0\n                skewness = 0\n            else:\n                kurtosis = np.mean((coeff - np.mean(coeff))**4) / (variance**2)\n                skewness = np.mean((coeff - np.mean(coeff))**3) / (variance**1.5)\n            energy = np.sum(np.square(coeff))\n            entropy = -np.sum(coeff * np.log2(np.abs(coeff) + 1e-12))\n            std_dev = np.std(coeff)\n            # Add features computed for each level\n            segment_features.extend([energy, entropy, kurtosis, skewness, std_dev])\n        \n        # MFCC feature extraction\n        segment_length = len(segment)\n        n_fft = min(2048, max(256, 2 ** int(np.floor(np.log2(segment_length)))))\n        mfccs = librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft)\n        mfcc_features = np.mean(mfccs, axis=1)  # Average over frames to get stable features\n\n        # Combine DWT and MFCC features\n        segment_features = segment_features + mfcc_features.tolist()\n        \n        # Add this segment's features to the sequence\n        sequence_features.append(segment_features)\n    \n    return np.array(sequence_features)\n\n\ndef create_sequences_fixed_segments_noise(data_dir, transcript_file, num_segments=20, n_mfcc=13):\n    \"\"\"\n    Function to create sequences of features and labels from audio files with fixed segmentation.\n    Parameters:\n    - data_dir: folder containing the audio files\n    - transcript_file: Excel file with transcripts and labels\n    - num_segments: fixed number of segments per audio\n    - n_mfcc: number of MFCC coefficients to extract per segment\n    Returns:\n    - features: numpy array with sequential features\n    - labels: numpy array with labels\n    \"\"\"\n    transcripts_df = pd.read_excel(transcript_file)\n    features = []\n    labels = []\n    \n    for _, row in tqdm(transcripts_df.iterrows(), total=transcripts_df.shape[0]):\n        audio_name = row['audio name']\n        label = row['label']\n        input_audio_path = os.path.join(data_dir, audio_name)\n        \n        try:\n            # Load audio file\n            signal, sample_rate = librosa.load(input_audio_path, sr=None)\n            \n            # Extract sequential features with fixed segmentation\n            sequence_features = preprocess_audio_sequential_fixed_segments(\n                signal, sample_rate, num_segments=num_segments, n_mfcc=n_mfcc\n            )\n            \n            features.append(sequence_features)\n            labels.append(label)\n        except:\n            print(\"Error while reading audio\")\n    \n    return np.array(features), np.array(labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Holdout","metadata":{}},{"cell_type":"code","source":"num_segments = 20  # Fixed number of segments for each audio\n\n# Train\ntrain_features, train_labels = create_sequences_fixed_segments_noise(train_audio_dir, train_transcript_file, num_segments)\nprint(f\"Train features shape: {train_features.shape}\")\nprint(f\"Train labels shape: {train_labels.shape}\")\n\n# Validation\nval_features, val_labels = create_sequences_fixed_segments_noise(val_audio_dir, val_transcript_file, num_segments)\nprint(f\"Validation features shape: {val_features.shape}\")\nprint(f\"Validation labels shape: {val_labels.shape}\")\n\n# Test\ntest_features, test_labels = create_sequences_fixed_segments_noise(test_audio_dir, test_transcript_file, num_segments)\nprint(f\"Test features shape: {test_features.shape}\")\nprint(f\"Test labels shape: {test_labels.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save features in npy files\nfolder_name = f\"audio_{num_segments}\"\nos.makedirs(f\"/kaggle/working/{folder_name}\", exist_ok=True)\n\n# Salva gli array per poterli utilizzare in seguito\nnp.save(f\"{folder_name}/train_features.npy\", train_features)\nnp.save(f\"{folder_name}/val_features.npy\", val_features)\nnp.save(f\"{folder_name}/test_features.npy\", test_features)\nnp.save(f\"{folder_name}/train_labels.npy\", train_labels)\nnp.save(f\"{folder_name}/val_labels.npy\", val_labels)\nnp.save(f\"{folder_name}/test_labels.npy\", test_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cross-Validation","metadata":{}},{"cell_type":"code","source":"features_by_fold = []\n\nfor fold in folds:\n    audio_dir = fold + \"/Audio\"\n    transcript_file = fold + \"/Transcripts/Transcripts.xlsx\"\n\n    features, labels = create_sequences_fixed_segments_noise(audio_dir, transcript_file, num_segments = num_segments)\n\n    features_by_fold.append((features,labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save features in npy files\nfor i in range(4):\n    np.save(f\"{folder_name}/fold_{i}_features.npy\", features_by_fold[i][0])\n    np.save(f\"{folder_name}/fold_{i}_labels.npy\", features_by_fold[i][1])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}